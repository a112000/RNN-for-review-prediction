{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3_Bychkov.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSTywc-WmRli"
      },
      "source": [
        "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 3. \n",
        "\n",
        "## –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏ –æ—Ç–µ–ª—è –ø–æ —Ç–µ–∫—Å—Ç—É –æ—Ç–∑—ã–≤–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqepILehmRl0"
      },
      "source": [
        "–ú—ã —Å–æ–±—Ä–∞–ª–∏ –¥–ª—è –≤–∞—Å –æ—Ç–∑—ã–≤—ã –ø–æ 1500 –æ—Ç–µ–ª—è–º –∏–∑ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã—Ö —É–≥–æ–ª–∫–æ–≤ –º–∏—Ä–∞. –ß—Ç–æ —ç—Ç–æ –∑–∞ –æ—Ç–µ–ª–∏ - —Å–µ–∫—Ä–µ—Ç. –í–∞–º –¥–∞–Ω —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –æ—Ç–µ–ª—è. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –Ω–∞—É—á–∏—Ç—å—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –æ—Ü–µ–Ω–∫—É –æ—Ç–µ–ª—è –ø–æ –æ—Ç–∑—ã–≤—É. –î–∞–Ω–Ω—ã–µ –º–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å [—Ç—É—Ç](https://www.kaggle.com/c/hseds-texts-2020/data?select=train.csv)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZGRS8aAmRl1"
      },
      "source": [
        "–ì–ª–∞–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ - Mean Absolute Error (MAE). –í–æ –≤—Å–µ—Ö —á–∞—Å—Ç—è—Ö –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç—ã –≤–∞–º –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ MAE –Ω–µ –ø—Ä–µ–≤—ã—à–∞—é—â–µ–µ 1. –í –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ –º—ã –±—É–¥–µ–º –≤—ã–Ω—É–∂–¥–µ–Ω—ã –Ω–µ –∑–∞—Å—á–∏—Ç–∞—Ç—å –∑–∞–¥–∞–Ω–∏–µ :( "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXIX2tIkmRl2"
      },
      "source": [
        "–î–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ train –∏ test –∏ –∑–∞–º–µ—Ä—è–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π —á–∞—Å—Ç–∏."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-VS6SW3mRl3"
      },
      "source": [
        "#### –ü—Ä–æ –¥–∞–Ω–Ω—ã–µ:\n",
        "–ö–∞–∂–¥–æ–µ —Ä–µ–≤—å—é —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤: positive –∏ negative - –ø–ª—é—Å—ã –∏ –º–∏–Ω—É—Å—ã –æ—Ç–µ–ª—è. –í —Å—Ç–æ–ª–±—Ü–µ score –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –æ—Ü–µ–Ω–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ 0 –¥–æ 10. –í–∞–º –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —ç—Ç–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –ø–æ –Ω–∏–º –æ—Ü–µ–Ω–∫—É."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6cwkhnQmRl3"
      },
      "source": [
        "–£–¥–∞—á–∏! üí™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzdv085EmRl4"
      },
      "source": [
        "#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–Ω–µ—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å—Ç—Ä–æ–≥–æ –∑–∞–ø—Ä–µ—â–µ–Ω–æ. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ torchvision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CczMB02XmRl5"
      },
      "source": [
        "PATH_TO_TRAIN_DATA = 'train.csv' # —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–∞–ª —á–µ—Ä–µ–∑ \"–∑–∞–≥—Ä—É–∑–∫—É –≤ —Å–µ—Å—Å–∏–æ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "iwHuZSD3mRl6",
        "outputId": "c7a8d48c-5e03-4626-ed6d-f0e4556d9ae9"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(PATH_TO_TRAIN_DATA)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00003c6036f30f590c0ac435efb8739b</td>\n",
              "      <td>There were issues with the wifi connection</td>\n",
              "      <td>No Positive</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00004d18f186bf2489590dc415876f73</td>\n",
              "      <td>TV not working</td>\n",
              "      <td>No Positive</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000cf900cbb8667fad33a717e9b1cf4</td>\n",
              "      <td>More pillows</td>\n",
              "      <td>Beautiful room Great location Lovely staff</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000df16edf19e7ad9dd8c5cd6f6925e</td>\n",
              "      <td>Very business</td>\n",
              "      <td>Location</td>\n",
              "      <td>5.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00025e1aa3ac32edb496db49e76bbd00</td>\n",
              "      <td>Rooms could do with a bit of a refurbishment ...</td>\n",
              "      <td>Nice breakfast handy for Victoria train stati...</td>\n",
              "      <td>6.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          review_id  ... score\n",
              "0  00003c6036f30f590c0ac435efb8739b  ...   7.1\n",
              "1  00004d18f186bf2489590dc415876f73  ...   7.5\n",
              "2  0000cf900cbb8667fad33a717e9b1cf4  ...  10.0\n",
              "3  0000df16edf19e7ad9dd8c5cd6f6925e  ...   5.4\n",
              "4  00025e1aa3ac32edb496db49e76bbd00  ...   6.7\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8bbzN9RmRl8"
      },
      "source": [
        "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –º–æ–∂–µ—Ç —Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏.\n",
        "–°–¥–µ–ª–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–æ–≤: —É–¥–∞–ª–∏–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –ø—Ä–∏–≤–µ–¥–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É. \n",
        "–û–¥–Ω–∞–∫–æ –º–æ–∂–Ω–æ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å—Å—è —ç—Ç–∏–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π. –ü–æ–¥—É–º–∞–π—Ç–µ, —á—Ç–æ –µ—â–µ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å —Ç–µ–∫—Å—Ç–∞–º–∏, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å –±—É–¥—É—â–∏–º –º–æ–¥–µ–ª—è–º? –î–æ–±–∞–≤—å—Ç–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –±—ã –ø–æ–º–æ—á—å –ø–æ –≤–∞—à–µ–º—É –º–Ω–µ–Ω–∏—é."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWILGf8rmRl8"
      },
      "source": [
        "–¢–∞–∫–∂–µ –º—ã –¥–æ–±–∞–≤–∏–ª–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —Ç–æ–∫–µ–Ω—ã. –¢–µ–ø–µ—Ä—å –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞-—Ä–µ–≤—å—é —Å—Ç–∞–ª–∞ –º–∞—Å—Å–∏–≤–æ–º —Ç–æ–∫–µ–Ω–æ–≤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Usb6VcwRmRl9",
        "outputId": "315d9fcc-4c57-4c89-aa94-1bfef22b54aa"
      },
      "source": [
        "import string\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def process_text(text):\n",
        "    return [word for word in word_tokenize(text.lower()) if word not in string.punctuation]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQF-eWsoX6Gf"
      },
      "source": [
        "########## SVOYI DOBAVLENIYA ########\r\n",
        "df_my = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh-KHlVUmRl9"
      },
      "source": [
        "#df['negative'] = df['negative'].apply(process_text) because TfidfVectorizer works with strings, not tokens.\n",
        "#df['positive'] = df['positive'].apply(process_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd_1rUZNmRl-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#df_train, df_test = train_test_split(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsq-N9PTaY0s"
      },
      "source": [
        "df_train, df_test = train_test_split(df_my, train_size=30000, test_size=10000, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NoPGDOqmRl-"
      },
      "source": [
        "### –ß–∞—Å—Ç—å 1. 1 –±–∞–ª–ª"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGRfgAOtmRl_"
      },
      "source": [
        "–û–±—É—á–∏—Ç–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ TF-IDF –≤–µ–∫—Ç–æ—Ä–∞—Ö —Ç–µ–∫—Å—Ç–æ–≤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti7RzS8jmRl_"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TWokV0leykC",
        "outputId": "e76f29a7-5610-4626-e624-e7f574c5864c"
      },
      "source": [
        "df_train['positive'] = 'positive: ' + df_train['positive'] + ' ' + df_train['negative'] + ' negative.' # concatenation two rows \r\n",
        "# into one (positive).\r\n",
        "df_test['positive'] = 'positive: ' + df_test['positive'] + ' ' + df_test['negative'] + ' negative.'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw5AMNLNPLk6"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\r\n",
        "train_x = vectorizer.fit_transform(df_train['positive']) # series type\r\n",
        "test_x = vectorizer.transform(df_test['positive'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6baGvlkk5nEl"
      },
      "source": [
        "train_y = df_train['score']\r\n",
        "test_y = df_test['score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLnDJeT8W9wg"
      },
      "source": [
        "train_x = train_x.toarray() # sparse matrix to array\r\n",
        "test_x = test_x.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "803vD5_46OI_"
      },
      "source": [
        "train_y = train_y.to_numpy() # series to array\r\n",
        "test_y = test_y.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYZ6jfNUeVKE"
      },
      "source": [
        "train_y = np.around(train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUoNgnYQfH8t"
      },
      "source": [
        "train_y = train_y.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2MrVXtk6LDF"
      },
      "source": [
        "–£ –º–µ–Ω—è fit —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 5 –º–∏–Ω—É—Ç."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgWG0VMQX7mg",
        "outputId": "38a19c7d-cdd6-49df-a3a1-e2e3a2182db9"
      },
      "source": [
        "log_reg = LogisticRegression().fit(train_x, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEbm4eCFZU9p"
      },
      "source": [
        "pred = log_reg.predict(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzUtaqlnZWPS",
        "outputId": "a43e02d9-03bd-43a1-a246-deef538a7f9e"
      },
      "source": [
        "mean_absolute_error(test_y, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97445"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7uBUO00mRmA"
      },
      "source": [
        "### –ß–∞—Å—Ç—å 2. 3 –±–∞–ª–ª–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29lPUrQ7mRmA"
      },
      "source": [
        "–û–±—É—á–∏—Ç–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã—Ö Word2Vec –≤–µ–∫—Ç–æ—Ä–∞—Ö. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQF1oPhYCB7W"
      },
      "source": [
        "np.set_printoptions(threshold=np.inf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkkTCDlpmRmA"
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoSj0MgGQxTw"
      },
      "source": [
        "df = pd.read_csv(PATH_TO_TRAIN_DATA)\r\n",
        "\r\n",
        "df['positive'] = 'positive: ' + df['positive'] + ' ' + df['negative'] + ' negative.' # concatenation two rows into one (positive).\r\n",
        "\r\n",
        "df['positive'] = df['positive'].apply(process_text)\r\n",
        "\r\n",
        "df_train, df_test = train_test_split(df, train_size=30000, test_size=10000, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_LzUhDmKfhJ"
      },
      "source": [
        "train_x = df_train['positive'] \r\n",
        "test_x = df_test['positive']\r\n",
        "\r\n",
        "train_y = df_train['score']\r\n",
        "test_y = df_test['score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJvAI96VcHEG"
      },
      "source": [
        "train_y = train_y.to_numpy() # series to array\r\n",
        "test_y = test_y.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yu8EBYHdddZ"
      },
      "source": [
        "train_y = np.around(train_y)\r\n",
        "train_y = train_y.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YwlItReBH2Z"
      },
      "source": [
        "train_x = train_x.to_numpy()\r\n",
        "test_x = test_x.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7CJOax7ATK8"
      },
      "source": [
        "emb_size = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xgUzpv0at52"
      },
      "source": [
        "–°–ª–µ–¥—É—é—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è, —Å—á–∏—Ç–∞—é—â–∞—è –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –∏–∑ —Å–ª–æ–≤–∞—Ä—è, —É –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –º–∏–Ω—É—Ç—ã 2. –ï–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∑–≤–æ–ª—è—é—Ç –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–∏–µ–º–ª–µ–º–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axU29sTaHQvO"
      },
      "source": [
        "model = Word2Vec(sentences=train_x, size=emb_size, sg=1, hs=1, window=11, iter=8, sample=0.001, alpha=0.030, min_count=3, min_alpha=0.0001, max_vocab_size=15000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNyBfihXMDBF",
        "outputId": "96537329-2a26-4e1d-e735-c25dd6b83ee3"
      },
      "source": [
        "X = model[model.wv.vocab]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9Fp16xONNbC"
      },
      "source": [
        "words = np.array(list(model.wv.vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1MAmxlCbEn1"
      },
      "source": [
        "–î–∞–ª–µ–µ - –¥–≤–∞ —Ü–∏–∫–ª–∞, –≥–¥–µ —É—Å—Ä–µ–¥–Ω—è—é—Ç—Å—è –≤–µ–∫—Ç–æ—Ä–∞ –≤ –∫–∞–∂–¥–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ (–æ—Ç–∑—ã–≤–µ). –î–ª–∏—Ç—Å—è —ç—Ç–æ –≤—Å–µ –º–∏–Ω—É—Ç—ã —á–µ—Ç—ã—Ä–µ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K2qiethN4LD"
      },
      "source": [
        "train_X = np.zeros((len(train_x), emb_size,))\r\n",
        "for i in range(len(train_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in train_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  train_X[i] = x / c\r\n",
        "  if np.isnan(train_X[i]).any():\r\n",
        "    train_X[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "test_X = np.zeros((len(test_x), emb_size,))\r\n",
        "for i in range(len(test_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in test_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  test_X[i] = x / c\r\n",
        "  if np.isnan(test_X[i]).any():\r\n",
        "    test_X[i] = np.zeros((emb_size,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNP8x_q9b-EG",
        "outputId": "0a353bb7-ec16-4bcf-bc98-30847a318cc2"
      },
      "source": [
        "log_reg = LogisticRegression(max_iter=300, penalty='none').fit(train_X, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3wgYTsnc5U1"
      },
      "source": [
        "pred = log_reg.predict(test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-Wo_3KJNHJD",
        "outputId": "f81fc98b-fac2-44d9-a1c4-d347376b1bf7"
      },
      "source": [
        "mean_absolute_error(test_y, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97896"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPaDhC99kBvP"
      },
      "source": [
        "–°–æ–∑–¥–∞—é –º–∞—Å—Å–∏–≤ —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –¥–ª–∏–Ω—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (–¥–ª—è —Ç—Ä–µ—Ö –∑–Ω–∞—á–µ–Ω–∏–π: 100, 300, 500) –∏ —Å –ª–æ—Å—Å–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ —Å –µ–¥–∏–Ω–∏—á–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ (–ø–æ–∫–∞ –Ω—É–ª–∏)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIvrm97uYwhP"
      },
      "source": [
        "emp_seq = [100, 300, 500]\r\n",
        "qual_zeroweight = [0, 0, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Y5RQ7HTcTz"
      },
      "source": [
        "qual_zeroweight[1] = mean_absolute_error(test_y, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f49cUInf72Qs",
        "outputId": "77bec953-2a17-4053-bb7d-c7108f24b153"
      },
      "source": [
        "mean_absolute_error(test_y, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9869399999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 724
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHTcdmRkmRmB"
      },
      "source": [
        "–£—Å—Ä–µ–¥–Ω—è—è w2v –≤–µ–∫—Ç–æ—Ä–∞, –º—ã –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –∏–º–µ–µ—Ç —Ä–∞–≤–Ω–æ—Ü–µ–Ω–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Å–º—ã—Å–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ–¥–Ω–∞–∫–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ —Å–æ–≤—Å–µ–º —Ç–∞–∫. –¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥—Ä—É–≥–æ–π –∫–æ–Ω—Ü–µ–ø—Ü–∏–µ–π –∏ –ø–µ—Ä–µ–≤–∑–≤–µ—Å–∏—Ç—å —Å–ª–æ–≤–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–∞. –í –∫–∞—á–µ—Å—Ç–≤–µ –≤–µ—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ IDF (Inverse document frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXnblXZWb3hQ"
      },
      "source": [
        "–î–∞–ª–µ–µ - —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤ (–≤–µ—Å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ - –æ—Ç 0,0001 –¥–æ —Ç—Ä—ë—Ö, —Å —É—á–µ—Ç–æ–º —Ä–∞–∑–º–µ—Ä–∞ —Ç—Ä–µ–π–Ω–∞ = 30000). –†–∞–±–æ—Ç–∞–µ—Ç –Ω–µ –º–∞–ª–æ, –ø—Ä–∏–º–µ—Ä–Ω–æ 4 –º–∏–Ω—É—Ç—ã."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ku6NS3zmRmB"
      },
      "source": [
        "def calc_idf(texts, vocab):\n",
        "    weights = np.zeros((len(vocab), ))\n",
        "    for j in range(len(vocab)):\n",
        "      freq = 0\n",
        "      for i in range(len(texts)):\n",
        "        if vocab[j] in texts[i]:\n",
        "          freq += 1\n",
        "      weights[j] = len(texts) / freq\n",
        "    weights = weights / 10000\n",
        "    return weights\n",
        "\n",
        "we = calc_idf(train_x, words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t709UV46c41u"
      },
      "source": [
        "–ü—Ä–æ—à—É –ø—Ä–æ—â–µ–Ω–∏—è –∑–∞ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∫—É—Å–∫–∏ –∫–æ–¥–∞ –¥–∞–ª—å—à–µ, —ç—Ç–æ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –∫—Ä–∞—Å–∏–≤–µ–µ –æ—Ñ–æ—Ä–º–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—è–º–∏, –Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzuESwq0kxKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17077b69-7209-441a-c772-dada80cd7b34"
      },
      "source": [
        "emb_size = 100\r\n",
        "model = Word2Vec(sentences=train_x, size=emb_size, sg=1, hs=1, window=11, iter=8, sample=0.001, alpha=0.030, min_count=3, min_alpha=0.0001, max_vocab_size=15000)\r\n",
        "X = model[model.wv.vocab]\r\n",
        "words = np.array(list(model.wv.vocab))\r\n",
        "\r\n",
        "train_XX = np.zeros((len(train_x), emb_size,))\r\n",
        "for i in range(len(train_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in train_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + we[np.where(words == word)[0][0]]*X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  train_XX[i] = x / c\r\n",
        "  if np.isnan(train_XX[i]).any():\r\n",
        "    train_XX[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "test_XX = np.zeros((len(test_x), emb_size,))\r\n",
        "for i in range(len(test_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in test_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + we[np.where(words == word)[0][0]]*X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  test_XX[i] = x / c\r\n",
        "  if np.isnan(test_XX[i]).any():\r\n",
        "    test_XX[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "log_reg = LogisticRegression(max_iter=300, penalty='none').fit(train_XX, train_y)\r\n",
        "pred_XX = log_reg.predict(test_XX)\r\n",
        "mean_absolute_error(test_y, pred_XX)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4048200000000002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRIBk30qjagt"
      },
      "source": [
        "–ù–∞ —ç—Ç–æ–º –º–æ–º–µ–Ω—Ç–µ —è —Ä–µ—à–∏–ª, —á—Ç–æ –ø–æ–∫–∞–∑–∞—Ç—å –ª–æ—Å—Å—ã –¥–ª—è —á–µ—Ç—ã—Ä–µ—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Ä–∞–∑–º–µ—Ä–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (100, 200, 300, 500) –±—É–¥–µ—Ç –Ω–∞–≥–ª—è–¥–Ω–µ–µ, —á–µ–º –¥–ª—è —Ç—Ä–µ—Ö, –ø–æ—ç—Ç–æ–º—É —Å–æ–∑–¥–∞–µ—Ç—Å—è –º–∞—Å—Å–∏–≤ –∏–∑ —á–µ—Ç—ã—Ä–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–¥–ª—è –º–æ–¥–µ–ª–∏ —Å –≥–∏–±–∫–∏–º–∏ –≤–µ—Å–∞–º–∏)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k7zYDYlZx2d"
      },
      "source": [
        "qual_flexweight = [0, 0, 0, 0]\r\n",
        "qual_flexweight[0] = mean_absolute_error(test_y, pred_XX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-YBUsK6YoxL",
        "outputId": "85de21e1-e1f2-4e40-8dd5-0969764da722"
      },
      "source": [
        "emb_size = 200\r\n",
        "model = Word2Vec(sentences=train_x, size=emb_size, sg=1, hs=1, window=11, iter=8, sample=0.001, alpha=0.030, min_count=3, min_alpha=0.0001, max_vocab_size=15000)\r\n",
        "X = model[model.wv.vocab]\r\n",
        "words = np.array(list(model.wv.vocab))\r\n",
        "\r\n",
        "train_XX = np.zeros((len(train_x), emb_size,))\r\n",
        "for i in range(len(train_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in train_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + we[np.where(words == word)[0][0]]*X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  train_XX[i] = x / c\r\n",
        "  if np.isnan(train_XX[i]).any():\r\n",
        "    train_XX[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "test_XX = np.zeros((len(test_x), emb_size,))\r\n",
        "for i in range(len(test_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in test_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + we[np.where(words == word)[0][0]]*X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  test_XX[i] = x / c\r\n",
        "  if np.isnan(test_XX[i]).any():\r\n",
        "    test_XX[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "log_reg = LogisticRegression(max_iter=300, penalty='none').fit(train_XX, train_y)\r\n",
        "pred_XX = log_reg.predict(test_XX)\r\n",
        "mean_absolute_error(test_y, pred_XX)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.39682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9xn3efQYtt0"
      },
      "source": [
        "qual_flexweight[1] = mean_absolute_error(test_y, pred_XX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1PaMT1EYxEg",
        "outputId": "37ca063c-5c61-418d-f23e-38fc124c254f"
      },
      "source": [
        "emb_size = 300\r\n",
        "model = Word2Vec(sentences=train_x, size=emb_size, sg=1, hs=1, window=11, iter=8, sample=0.001, alpha=0.030, min_count=3, min_alpha=0.0001, max_vocab_size=15000)\r\n",
        "X = model[model.wv.vocab]\r\n",
        "words = np.array(list(model.wv.vocab))\r\n",
        "\r\n",
        "train_XX = np.zeros((len(train_x), emb_size,))\r\n",
        "for i in range(len(train_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in train_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + we[np.where(words == word)[0][0]]*X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  train_XX[i] = x / c\r\n",
        "  if np.isnan(train_XX[i]).any():\r\n",
        "    train_XX[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "test_XX = np.zeros((len(test_x), emb_size,))\r\n",
        "for i in range(len(test_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in test_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + we[np.where(words == word)[0][0]]*X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  test_XX[i] = x / c\r\n",
        "  if np.isnan(test_XX[i]).any():\r\n",
        "    test_XX[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "log_reg = LogisticRegression(max_iter=300, penalty='none').fit(train_XX, train_y)\r\n",
        "pred_XX = log_reg.predict(test_XX)\r\n",
        "mean_absolute_error(test_y, pred_XX)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.39178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BewjAgQvY0LU"
      },
      "source": [
        "qual_flexweight[2] = mean_absolute_error(test_y, pred_XX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRGqaSxGY26K",
        "outputId": "99ecb46a-84d0-4e37-8494-710abd316a43"
      },
      "source": [
        "emb_size = 500\r\n",
        "model = Word2Vec(sentences=train_x, size=emb_size, sg=1, hs=1, window=11, iter=8, sample=0.001, alpha=0.030, min_count=3, min_alpha=0.0001, max_vocab_size=15000)\r\n",
        "X = model[model.wv.vocab]\r\n",
        "words = np.array(list(model.wv.vocab))\r\n",
        "\r\n",
        "train_XX = np.zeros((len(train_x), emb_size,))\r\n",
        "for i in range(len(train_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in train_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + we[np.where(words == word)[0][0]]*X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  train_XX[i] = x / c\r\n",
        "  if np.isnan(train_XX[i]).any():\r\n",
        "    train_XX[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "test_XX = np.zeros((len(test_x), emb_size,))\r\n",
        "for i in range(len(test_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in test_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + we[np.where(words == word)[0][0]]*X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  test_XX[i] = x / c\r\n",
        "  if np.isnan(test_XX[i]).any():\r\n",
        "    test_XX[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "log_reg = LogisticRegression(max_iter=300, penalty='none').fit(train_XX, train_y)\r\n",
        "pred_XX = log_reg.predict(test_XX)\r\n",
        "mean_absolute_error(test_y, pred_XX)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.39852"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_NrJtcyY6cC"
      },
      "source": [
        "qual_flexweight[3] = mean_absolute_error(test_y, pred_XX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe-pZDgVaTQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0365b2e3-5fdd-4c59-f15c-f797dcac7bca"
      },
      "source": [
        "emb_size = 500\r\n",
        "model = Word2Vec(sentences=train_x, size=emb_size, sg=1, hs=1, window=11, iter=8, sample=0.001, alpha=0.030, min_count=3, min_alpha=0.0001, max_vocab_size=15000)\r\n",
        "X = model[model.wv.vocab]\r\n",
        "words = np.array(list(model.wv.vocab))\r\n",
        "\r\n",
        "train_X = np.zeros((len(train_x), emb_size,))\r\n",
        "for i in range(len(train_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in train_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  train_X[i] = x / c\r\n",
        "  if np.isnan(train_X[i]).any():\r\n",
        "    train_X[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "test_X = np.zeros((len(test_x), emb_size,))\r\n",
        "for i in range(len(test_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in test_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  test_X[i] = x / c\r\n",
        "  if np.isnan(test_X[i]).any():\r\n",
        "    test_X[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "log_reg = LogisticRegression(max_iter=300, penalty='none').fit(train_X, train_y)\r\n",
        "pred = log_reg.predict(test_X)\r\n",
        "mean_absolute_error(test_y, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Tk2RnYTPrH"
      },
      "source": [
        "qual_zeroweight[2] = mean_absolute_error(test_y, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-PNhYTfTrfQ",
        "outputId": "2300aed9-a0d0-49f7-aadb-7c9d27a71d05"
      },
      "source": [
        "emb_size = 100\r\n",
        "model = Word2Vec(sentences=train_x, size=emb_size, sg=1, hs=1, window=11, iter=8, sample=0.001, alpha=0.030, min_count=3, min_alpha=0.0001, max_vocab_size=15000)\r\n",
        "X = model[model.wv.vocab]\r\n",
        "words = np.array(list(model.wv.vocab))\r\n",
        "\r\n",
        "train_X = np.zeros((len(train_x), emb_size,))\r\n",
        "for i in range(len(train_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in train_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  train_X[i] = x / c\r\n",
        "  if np.isnan(train_X[i]).any():\r\n",
        "    train_X[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "test_X = np.zeros((len(test_x), emb_size,))\r\n",
        "for i in range(len(test_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in test_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  test_X[i] = x / c\r\n",
        "  if np.isnan(test_X[i]).any():\r\n",
        "    test_X[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "log_reg = LogisticRegression(max_iter=300, penalty='none').fit(train_X, train_y)\r\n",
        "pred = log_reg.predict(test_X)\r\n",
        "mean_absolute_error(test_y, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0123000000000002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UPHg0N0VxJ0"
      },
      "source": [
        "qual_zeroweight[0] = mean_absolute_error(test_y, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMgjIREvU-Fc",
        "outputId": "7c7b17f6-12ff-413d-a5de-9dab9ec7803a"
      },
      "source": [
        "emb_size = 200\r\n",
        "model = Word2Vec(sentences=train_x, size=emb_size, sg=1, hs=1, window=11, iter=8, sample=0.001, alpha=0.030, min_count=3, min_alpha=0.0001, max_vocab_size=15000)\r\n",
        "X = model[model.wv.vocab]\r\n",
        "words = np.array(list(model.wv.vocab))\r\n",
        "\r\n",
        "train_X = np.zeros((len(train_x), emb_size,))\r\n",
        "for i in range(len(train_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in train_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  train_X[i] = x / c\r\n",
        "  if np.isnan(train_X[i]).any():\r\n",
        "    train_X[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "test_X = np.zeros((len(test_x), emb_size,))\r\n",
        "for i in range(len(test_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in test_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  test_X[i] = x / c\r\n",
        "  if np.isnan(test_X[i]).any():\r\n",
        "    test_X[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "log_reg = LogisticRegression(max_iter=300, penalty='none').fit(train_X, train_y)\r\n",
        "pred = log_reg.predict(test_X)\r\n",
        "mean_absolute_error(test_y, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9937800000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf7AX8IjkqNQ"
      },
      "source": [
        "–¢.–∫. –∫ —ç—Ç–æ–º—É –º–æ–º–µ–Ω—Ç—É —É–∂–µ —Ä–µ—à–µ–Ω–æ –¥–µ–ª–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è —á–µ—Ç—ã—Ä–µ—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª–∏–Ω—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–∞, —Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –º–∞—Å—Å–∏–≤ (–¥–ª—è –º–æ–¥–µ–ª–∏ —Å –µ–¥–∏–Ω–∏—á–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏), –¥–æ–ø–æ–ª–Ω–∏—Ç—å –æ–¥–Ω–∏–º –ø–æ—Å—á–∏—Ç–∞–Ω–Ω—ã–º —Ç–æ–ª—å–∫–æ —á—Ç–æ –ª–æ—Å—Å–æ–º –∏ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å —Ç—É–¥–∞ —É–∂–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ –ª–æ—Å—Å—ã."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvfAwcpkVkt2"
      },
      "source": [
        "qual_zerowe = [0, 0, 0, 0]\r\n",
        "qual_zerowe[1] = mean_absolute_error(test_y, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utvAStgXVIJ1"
      },
      "source": [
        "qual_zerowe[0] = qual_zeroweight[0]\r\n",
        "qual_zerowe[2] = qual_zeroweight[1]\r\n",
        "qual_zerowe[3] = qual_zeroweight[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z54aB0DKmRmB"
      },
      "source": [
        "–ü—Ä–æ–≤–µ–¥–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é —ç–º–±–µ–¥–¥–∏–Ω–≥–∞. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ –¥–≤—É—Ö –º–µ—Ç–æ–¥–æ–≤ –ø–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7ZjAEv2sWSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c59f9975-8486-49da-d21b-6b8f1fd1f3dd"
      },
      "source": [
        "import matplotlib.pyplot as plt  \r\n",
        "  \r\n",
        "x = [100, 200, 300, 500]   \r\n",
        "plt.plot(x, qual_zerowe)  \r\n",
        "plt.xlabel('Embedding size')    \r\n",
        "plt.ylabel('Los') # Loss* \r\n",
        "plt.title('Word2Vec with zero weights') # –æ–ø–µ—á–∞—Ç–∫–∞: —ç—Ç–æ –Ω–µ zero weights, –∞ –µ–¥–∏–Ω–∏—á–Ω—ã–µ weights \r\n",
        "plt.show()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fHOQQho6TF4_",
        "outputId": "02ebf8aa-8caa-4f88-d790-27f3a2077ac4"
      },
      "source": [
        "x = [100, 200, 300, 500] \r\n",
        "plt.plot(x, qual_flexweight)  \r\n",
        "plt.xlabel('Embedding size')    \r\n",
        "plt.ylabel('Loss')  \r\n",
        "plt.title('Word2Vec with flexible weights')  \r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72CyjgZ8sUvn"
      },
      "source": [
        "#### –°–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥—ã:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa6aPzayeQrA"
      },
      "source": [
        "–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –≤–∑–≤–µ—à–µ–Ω–Ω—ã—Ö word2vec —è–≤–Ω–æ —Ö—É–∂–µ, —á–µ–º –ø—Ä–∏ –µ–¥–∏–Ω–∏—á–Ω—ã—Ö –≤–µ—Å–∞—Ö. –≠—Ç–æ –º–æ–∂–µ—Ç –ø–æ–∫–∞–∑–∞—Ç—å—Å—è —Å—Ç—Ä–∞–Ω–Ω—ã–º, —Ç–∫ –±–æ–ª–µ–µ —Ä–µ–¥–∫–∏–µ —Å–ª–æ–≤–∞ –ø—Ä–∏ –≥–∏–±–∫–∏—Ö –≤–µ—Å–∞—Ö —Å–∏–ª—å–Ω–µ–µ –≤–ª–∏—è—é—Ç –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ. –û–¥–Ω–∞–∫–æ, –µ—Å–ª–∏ –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∏–µ–Ω—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ —Å–ª–æ–≤–∞, –æ–ø–∏—Å—ã–≤–∞—è —Ä–∞–∑–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏–ª–∏ –¥–µ—Ç–∞–ª–∏ –æ—Ç–µ–ª–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä: great, bad, comfortable, fabulous, tremendous, awful), —Ç–æ —É–∂–µ —ç—Ç–∏ —Å–ª–æ–≤–∞-—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –±—É–¥—É—Ç –∏–º–µ—Ç—å –±–æ–ª–µ–µ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –ø–æ–≤—Ç–æ—Ä—è—è—Å—å –¥–æ–≤–æ–ª—å–Ω–æ —á–∞—Å—Ç–æ. \r\n",
        "\r\n",
        "–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–∞ = 300 –¥–ª—è –æ–±–æ–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –≤–µ—Å–æ–≤. –ü–æ –≤—Å–µ–π –≤–∏–¥–∏–º–æ—Å—Ç–∏, –∏–º–µ–Ω–Ω–æ –ø—Ä–∏ —Ç–∞–∫–æ–º —Ä–∞–∑–º–µ—Ä–µ –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –æ—Ç–∑—ã–≤–æ–≤, –ø–æ—Ö–æ–∂–µ –æ–ø–∏—Å—ã–≤–∞—é—â–∏—Ö –æ—Ç–µ–ª—å (–∏ –∏–º–µ—é—â–∏—Ö –ø–æ—Ö–æ–∂–∏–µ –æ—Ü–µ–Ω–∫–∏), –≤—Å–µ –µ—â–µ –ø–æ—Ö–æ–∂–∏ –¥—Ä—É–≥ –Ω–∞ –¥—Ä—É–≥–∞, –Ω–æ —É–∂–µ –Ω–µ –ø–æ—Ö–æ–∂–∏ –Ω–∞ –≤–µ–∫—Ç–æ—Ä–∞ –æ—Ç–∑—ã–≤–æ–≤, –æ–ø–∏—Å—ã–≤–∞—é—â–∏—Ö –æ—Ç–µ–ª—å –ø–æ-–¥—Ä—É–≥–æ–º—É (–∏–º–µ—é—â–∏—Ö –∏–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waB9cDqjmRmC"
      },
      "source": [
        "–¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±—É—á–∏—Ç—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 300 –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å Word2Vec."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n7PsIpIsGM1"
      },
      "source": [
        "from gensim.models import FastText\r\n",
        "# from gensim.models.wrappers import Wordrank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3Cc-XDssPQz"
      },
      "source": [
        "emb_size = 300\r\n",
        "model_fast = FastText(sentences=train_x, size=emb_size, window=8, sg=1, hs=1, iter=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6k3FhYej4y6",
        "outputId": "f257ec5a-0ec9-4994-9b1e-ddda852bf040"
      },
      "source": [
        "X = model_fast[model_fast.wv.vocab]\r\n",
        "words = np.array(list(model_fast.wv.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7m5UVcYk2y2"
      },
      "source": [
        "train_XXX = np.zeros((len(train_x), emb_size,))\r\n",
        "for i in range(len(train_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in train_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  train_XXX[i] = x / c\r\n",
        "  if np.isnan(train_XXX[i]).any():\r\n",
        "    train_XXX[i] = np.zeros((emb_size,))\r\n",
        "\r\n",
        "test_XXX = np.zeros((len(test_x), emb_size,))\r\n",
        "for i in range(len(test_x)):\r\n",
        "  x = np.zeros((emb_size,))\r\n",
        "  c = 0\r\n",
        "  for word in test_x[i]:\r\n",
        "    if word in words:\r\n",
        "      x = x + X[np.where(words == word)[0][0]]\r\n",
        "      c += 1\r\n",
        "  test_XXX[i] = x / c\r\n",
        "  if np.isnan(test_XXX[i]).any():\r\n",
        "    test_XXX[i] = np.zeros((emb_size,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgA5T-SYoe2f",
        "outputId": "e84a8205-5a2e-4467-a326-dc584b447743"
      },
      "source": [
        "log_reg = LogisticRegression(max_iter=300, penalty='none').fit(train_XXX, train_y)\r\n",
        "pred_XXX = log_reg.predict(test_XXX)\r\n",
        "mean_absolute_error(test_y, pred_XXX)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98077"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36S8kkDWsIaF"
      },
      "source": [
        "#### –í—ã–≤–æ–¥—ã:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5AhMpWOsvQC"
      },
      "source": [
        "FastText, –∫–∞–∫ –∏ –º–æ–≥–ª–æ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—Ç—å—Å—è, –≤—ã–¥–∞–µ—Ç –ø—Ä–∏–µ–º–ª–µ–º–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –±–µ–∑ –∫–∞–∫–æ–≥–æ-—Ç–æ —Å–∫—É—Ä–ø—É–ª–µ–∑–Ω–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—á–µ–≥–æ –Ω–µ —Å–∫–∞–∂–µ—à—å –æ–± –æ–±—ã—á–Ω–æ–º word2vec). –≠—Ç–æ –ª–æ–≥–∏—á–Ω–æ, –≤–µ–¥—å fasttext –±–æ–ª–µ–µ –≥–∏–±–æ–∫, —Ç.–∫. —Å–æ–∑–¥–∞–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è —á–∞—Å—Ç–µ–π —Å–ª–æ–≤, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–ª–æ–≤ —Ü–µ–ª–∏–∫–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–ª–æ–≤–∞ bad –∏ badly –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é —á–∞c—Ç—å bad, –ø—Ä–∏ —Ç–æ–º, —á—Ç–æ –æ–±–∞ —Å–ª–æ–≤–∞ –Ω–µ—Å—É—Ç –Ω–µ–≥–∞—Ç–∏–≤–Ω—É—é –æ–∫—Ä–∞—Å–∫—É –∏, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –±—É–¥—É—Ç —Å–∏–≥–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ –±–æ–ª–µ–µ –Ω–∏–∑–∫–æ–π –æ—Ü–µ–Ω–∫–µ –æ—Ç –∫–ª–∏–µ—Ç–∞)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6soYY3fmRmC"
      },
      "source": [
        "### –ß–∞—Å—Ç—å 3. 6 –±–∞–ª–ª–æ–≤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqT7kMqKmRmC"
      },
      "source": [
        "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –ø—Ä–æ—Ö–æ–¥–∏–ª–∏ –≤ –Ω–∞—à–µ–º –∫—É—Ä—Å–µ. –û–±—É—á–∏—Ç–µ RNN/Transformer –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏. –ü–æ–ª—É—á–∏—Ç–µ –æ—à–∏–±–∫—É –º–µ–Ω—å—à–µ, —á–µ–º –≤–æ –≤—Å–µ—Ö –≤—ã—à–µ–ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–∞—Ö."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlhJj2KtmRmC"
      },
      "source": [
        "–ï—Å–ª–∏ –±—É–¥–µ—Ç–µ –æ–±—É—á–∞—Ç—å RNN, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–∑—ã–≤—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö.\n",
        "\n",
        "–ß—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è DataLoader, –≤—Å–µ –µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏. –î–ª—è —ç—Ç–æ–≥–æ –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –Ω—É–ª–µ–≤–æ–π –ø–∞–¥–¥–∏–Ω–≥ –∫–æ –≤—Å–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (—Å–º –ø—Ä–∏–º–µ—Ä pad_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA4jFpUlmRmD"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_-N9upbmRmD"
      },
      "source": [
        "WORDS = set()\n",
        "for sent in list(df['positive']):\n",
        "    for w in sent:\n",
        "        WORDS.add(w)\n",
        "        \n",
        "### –£ –Ω–∞—Å —É–∂–µ —Å–∫–ª–µ–µ–Ω—ã positive –∏ negative –≤ —Å—Ç–æ–ª–±—Ü–µ positive, –ø–æ—ç—Ç–æ–º—É —Ä–∞–±–æ—Ç–∞—Ç—å —Å negative –Ω–µ—Ç —Å–º—ã—Å–ª–∞ ###  \n",
        "\n",
        "#for sent in list(df['negative']): \n",
        "#    for w in sent:\n",
        "#        WORDS.add(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KiJ8E9smRmD"
      },
      "source": [
        "int2word = dict(enumerate(tuple(WORDS)))\n",
        "word2int = {w: ii for ii, w in int2word.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hy6PSKjmRmE"
      },
      "source": [
        "MAX_LEN = max(max(df['positive'].apply(len)), max(df['negative'].apply(len)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fXeip_9mRmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6382afea-0ba2-4b3d-fa06-4b4bee6e7d80"
      },
      "source": [
        "MAX_LEN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnuBMaWxxiRp"
      },
      "source": [
        "vocab = len(WORDS) # –î–ª–∏–Ω–∞ —Å–ª–æ–≤–∞—Ä—è"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WyHIVtV5XiN"
      },
      "source": [
        "### –ó–∞–Ω–æ–≤–æ –≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –≤–æ –≤—Ç–æ—Ä–æ–º –∑–∞–¥–∞–Ω–∏–∏ ###\r\n",
        "df = pd.read_csv(PATH_TO_TRAIN_DATA)\r\n",
        "df['positive'] = 'positive: ' + df['positive'] + ' ' + df['negative'] + ' negative.' # concatenation two rows into one (positive).\r\n",
        "df['positive'] = df['positive'].apply(process_text)\r\n",
        "df_train, df_test = train_test_split(df, train_size=30000, test_size=10000)\r\n",
        "train_y = df_train['score']\r\n",
        "test_y = df_test['score']\r\n",
        "train_y = train_y.to_numpy() # series to array\r\n",
        "test_y = test_y.to_numpy()\r\n",
        "train_y = np.around(train_y)\r\n",
        "train_y = train_y.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GwtlWfQmRmF"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "### –û–≥—Ä–∞–Ω–∏—á–∏–º –æ—Ç–∑—ã–≤—ã –¥–ª–∏–Ω–æ–π = MAX_REV ###\n",
        "MAX_REV = 60\n",
        "train_pos_pad = pad_sequence([torch.as_tensor([word2int[w] for w in seq][:MAX_REV]) for seq in df_train['positive']], \n",
        "                           batch_first=True)\n",
        "### –¢–æ –∂–µ —Å–∞–º–æ–µ –¥–ª—è test ###\n",
        "test_pos_pad = pad_sequence([torch.as_tensor([word2int[w] for w in seq][:MAX_REV]) for seq in df_test['positive']], \n",
        "                           batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq8yR4nveMhK"
      },
      "source": [
        "class ReviewsDataset(Dataset):\r\n",
        "    def __init__(self, X, Y):\r\n",
        "        self.X = X\r\n",
        "        self.y = Y\r\n",
        "        \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.y)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return self.X[idx], self.y[idx], 60 # –¢—Ä–µ—Ç–∏–π –≤—ã—Ö–æ–¥ –∏–¥—ë—Ç –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é l, –∫–æ—Ç–æ—Ä–∞—è –Ω–∏–∫–∞–∫ –Ω–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è, –ø–æ—ç—Ç–æ–º—É –ø–∏—à–µ–º –ª—é–±–æ–µ —á–∏—Å–ª–æ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws6FO4nNihC2"
      },
      "source": [
        "train_ds = ReviewsDataset(train_pos_pad, train_y)\r\n",
        "valid_ds = ReviewsDataset(test_pos_pad, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYxXSvthiuJ0"
      },
      "source": [
        "batch_size = 128\r\n",
        "vocab_size = vocab\r\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\r\n",
        "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFEOn0hhjHHB"
      },
      "source": [
        "def train_model_regr(model, epochs=10, lr=0.001):\r\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\r\n",
        "    optimizer = torch.optim.Adam(parameters, lr=lr) # –∫–∞–∫ –≤—Å–µ–≥–¥–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ê–¥–∞–º–∞\r\n",
        "    for i in range(epochs):\r\n",
        "        model.train()\r\n",
        "        sum_loss = 0.0\r\n",
        "        total = 0\r\n",
        "        for x, y, l in train_dl:\r\n",
        "            x = x.type(torch.LongTensor)\r\n",
        "            y = y.type(torch.FloatTensor)\r\n",
        "            y_pred = model(x, l)\r\n",
        "            y_pred = y_pred.view(y_pred.shape[0])\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss = F.mse_loss(y_pred, y) \r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            sum_loss += loss.item()*y.shape[0]\r\n",
        "            total += y.shape[0]\r\n",
        "        val_loss, val_loss_mae = validation_metrics_regr(model, val_dl) # –ø–æ–¥—Å—á–µ—Ç MSE –∏ MAE\r\n",
        "        if i % 5 == 1:\r\n",
        "            print(\"train mse %.3f val rmse %.3f val mae %.3f\" % (sum_loss/total, val_loss, val_loss_mae))\r\n",
        "\r\n",
        "def validation_metrics_regr (model, valid_dl):\r\n",
        "    model.eval()\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    sum_loss = 0.0\r\n",
        "    sum_loss_mae = 0.0\r\n",
        "    for x, y, l in valid_dl:\r\n",
        "        x = x.type(torch.LongTensor)\r\n",
        "        y = y.type(torch.FloatTensor)\r\n",
        "        y_hat = model(x, l)\r\n",
        "        y_hat = y_hat.view(y_hat.shape[0])\r\n",
        "        loss = np.sqrt(F.mse_loss(y_hat.detach(), y).item())\r\n",
        "        loss_mae = mean_absolute_error(y, y_hat.detach()).item()\r\n",
        "        total += 1 \r\n",
        "        sum_loss += loss.item() \r\n",
        "        sum_loss_mae += loss_mae \r\n",
        "    return sum_loss/total, sum_loss_mae/total\r\n",
        "\r\n",
        "### –ú–æ–¥–µ–ª—å - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤ –≤–µ–∫—Ç–æ—Ä–∞–º–∏, ###\r\n",
        "### –≤—ã–∫–∏–¥—ã–≤–∞–Ω–∏–µ —Å–ª—É—á–∞–π–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0,2, —Å–ª–æ–π LSTM –∏ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å –æ–¥–∏–º –≤—ã—Ö–æ–¥–æ–º –∫–∞–∫ –ø—Ä–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ ###\r\n",
        "class LSTM_regr(torch.nn.Module) :\r\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\r\n",
        "        super().__init__()\r\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\r\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\r\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\r\n",
        "        self.dropout = nn.Dropout(0.2)\r\n",
        "        \r\n",
        "    def forward(self, x, l):\r\n",
        "        x = self.embeddings(x)\r\n",
        "        x = self.dropout(x)\r\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\r\n",
        "        return self.linear(ht[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3CKVIlWkIAA"
      },
      "source": [
        "model_regr = LSTM_regr(vocab_size, 300, 50) # –∑–∞–¥–∞–¥–∏–º –¥–ª–∏–Ω—É –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è=300 –∏ —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ LSTM=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAvY-l-p-ubN"
      },
      "source": [
        "–¢—Ä–µ–Ω–∏—Ä—É–µ—Ç—Å—è —ç—Ç–∞ —à—Ç—É–∫–∞ –º–∏–Ω—É—Ç 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7pxYR1sUvd5",
        "outputId": "4f6564dd-e708-431b-bb6f-7137050e4b48"
      },
      "source": [
        "train_model_regr(model_regr, epochs=15, lr=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train mse 2.794 val rmse 1.609 val mae 1.296\n",
            "train mse 1.606 val rmse 1.255 val mae 0.949\n",
            "train mse 1.147 val rmse 1.208 val mae 0.890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXkb60ajzaRP"
      },
      "source": [
        "–î—Ä—É–≥–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å –¥–≤–∞–¥—Ü–∞—Ç—å—é —ç–ø–æ—Ö–∞–º–∏:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_zID4UqW4KW",
        "outputId": "a051defb-fdeb-475c-a8f6-204a816f03c7"
      },
      "source": [
        "train_model_regr(model_regr, epochs=20, lr=0.0007)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train mse 2.659 val rmse 1.623 val mae 1.311\n",
            "train mse 1.354 val rmse 1.168 val mae 0.883\n",
            "train mse 1.089 val rmse 1.130 val mae 0.854\n",
            "train mse 0.950 val rmse 1.125 val mae 0.840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly5mSFvq1n9t"
      },
      "source": [
        "–ü–æ—Ö–æ–∂–µ, —á—Ç–æ RNN —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ (–∏ –¥–æ–ª—å—à–µ) –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏, —á—Ç–æ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç—Å—è –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è–º–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π.\r\n",
        "\r\n",
        "–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–æ–º–∞—à–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏: \"How to Develop Word Embeddings in Python with Gensim\" –æ—Ç Jason Brownlee, \"Multiclass Text Classification using LSTM in Pytorch\" –æ—Ç Aakanksha NS, –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç—ã –ø–æ —Å—Å—ã–ª–∫–∞–º https://stackoverflow.com/questions/26576524/how-do-i-transform-a-scipy-sparse-matrix-to-a-numpy-matrix, https://stackoverrun.com/ru/q/401345."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t_7VElNmRmH"
      },
      "source": [
        "### –ë–æ–Ω—É—Å. 10 –±–∞–ª–ª–æ–≤\n",
        "\n",
        "–ü–æ–±–µ–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ 0.75 –≤ [—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–∏](https://www.kaggle.com/c/hseds-texts-2020/leaderboard). –ú–æ–∂–µ—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤—ã—à–µ–ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –∏–ª–∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —á—Ç–æ-–Ω–∏–±—É–¥—å –µ—â–µ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFdx-jCbmRmH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}